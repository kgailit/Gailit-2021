{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "failing-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import string \n",
    "import nltk\n",
    "from collections import Counter\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "lesser-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faili_info_salvestamine(filename):\n",
    "    global keskmised\n",
    "    \n",
    "    # Loob failinimed\n",
    "    ga_name = os.path.join(\"etnc19_web_2019_morf_oletamisega/\", \".\".join(filename.split(\".\")[:-1]) + \"_morf_oletamisega.json\")\n",
    "    ta_name = os.path.join(\"etnc19_web_2019_morf_oletamiseta/\", \".\".join(filename.split(\".\")[:-1]) + \"_morf_oletamiseta.json\")\n",
    "    meta_name = os.path.join(\"etnc19_web_2019_meta/\", \".\".join(filename.split(\".\")[:-1]) + \"_meta.json\")\n",
    "    \n",
    "    andmed_name = os.path.join(\"etnc19_web_2019_andmed/\", \".\".join(filename.split(\".\")[:-1]) + \"_meta.json\")\n",
    "    \n",
    "    # Loeb failidest sisse tekstid ja metainfo\n",
    "    oletamisega = None\n",
    "    oletamiseta = None\n",
    "    meta_info = None\n",
    "    with open(ga_name, \"r\", encoding = \"utf-8\") as fr:\n",
    "        oletamisega = Text(json.load(fr))\n",
    "    with open(ta_name, \"r\", encoding = \"utf-8\") as fr:\n",
    "        oletamiseta = Text(json.load(fr))\n",
    "    with open(meta_name, \"r\", encoding = \"utf-8\") as fr:\n",
    "        meta_info = json.load(fr)\n",
    "    \n",
    "    # Väljastatavate andmete sõnastik\n",
    "    andmed = defaultdict(float)\n",
    "    \n",
    "    # Metainfost oluliste andmete meelde jätmine\n",
    "    andmed[\"emotikonide_arv\"] = meta_info[\"emotikonide_arv\"]\n",
    "    \n",
    "    # Keskmistest varieerimise arvutamine\n",
    "    andmed[\"TTR_varieerumine\"] = meta_info[\"TTR\"] - keskmised['TTR']\n",
    "    andmed[\"käändsõnade_varieerumine\"] = meta_info[\"käänduvate_lemmade_osaarv\"] - keskmised['käänduvate_lemmade_osaarv']\n",
    "    andmed[\"lemmapikkuse_varieerumine\"] = meta_info[\"keskmine_lemma_pikkus\"] - keskmised['keskmine_lemma_pikkus']\n",
    "    \n",
    "    # Arvutab tajuverbide osaarvu kõikidest verbidest ja jätab meelde\n",
    "    andmed['tajuverbide_osaarv'] = tajuverbide_keskmine(oletamisega)\n",
    "    \n",
    "    # Arvutab lühikeste tundmatu morfanalüüsi saanud sõnade osaarvu\n",
    "    andmed['luhemate_tundmatute_osakaal'] = luhemate_tundmatute_osakaal(oletamiseta)\n",
    "    \n",
    "    # Loendab kokku vähemalt kolm korda korduvad tähed sõna sees\n",
    "    andmed['korduvate_tähtede_arv'] = leia_korduvad_tähed(oletamisega)\n",
    "    \n",
    "    # Leiab verbide isikute protsendid (kui palju on 1., 2. ja 3. isik)\n",
    "    verbide_isikute_protsendid = verbide_isikute_osakaalud(oletamisega)\n",
    "    andmed['verbide_esimese_isiku_osaarv'] = verbide_isikute_protsendid[0]\n",
    "    andmed['verbide_teise_isiku_osaarv'] = verbide_isikute_protsendid[1]\n",
    "    andmed['verbide_kolmanda_isiku_osaarv'] = verbide_isikute_protsendid[2]\n",
    "    \n",
    "    # Leiab asesõnade isikute protsendid (kui palju on 1., 2. ja 3. isik)\n",
    "    asesonade_isikute_protsendid = asesonade_isikute_osakaalud(oletamisega)\n",
    "    andmed['asesõnade_esimese_isiku_osaarv'] = asesonade_isikute_protsendid[0]\n",
    "    andmed['asesõnade_teise_isiku_osaarv'] = asesonade_isikute_protsendid[1]\n",
    "    andmed['asesõnade_kolmanda_isiku_osaarv'] = asesonade_isikute_protsendid[2]\n",
    "    \n",
    "    # Leiab passiivi osakaalu ja jätab meelde\n",
    "    andmed['passiivi_osakaal'] = passiivi_osakaal(oletamisega)\n",
    "    \n",
    "    # Kirjutab metainfo tagasi faili edasiseks skoori arvutamiseks\n",
    "    with open(andmed_name, 'w', encoding=\"UTF-8\") as fw:\n",
    "        json.dump(andmed, fw, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indian-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tajuverbide keskmise arvutamine\n",
    "def tajuverbide_keskmine(oletamisega):\n",
    "    with open(\"Loendid\\\\tajuverbid\\wordnet_tajuverbid.txt\", \"r\", encoding = \"utf8\") as fr:\n",
    "        lines = fr.readlines()\n",
    "        tajuverbid = [verb.strip() for verb in lines]\n",
    "        \n",
    "    all_verbs = 0\n",
    "    only_tajuverbs = 0\n",
    "\n",
    "    for lemma, postag in zip(oletamisega.lemmas, oletamisega.postags):\n",
    "        if postag == \"V\":\n",
    "            all_verbs += 1\n",
    "            if lemma in tajuverbid:\n",
    "                only_tajuverbs += 1\n",
    "\n",
    "    return only_tajuverbs / float(all_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "competitive-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korduvate tähtede leidmine\n",
    "def leia_korduvad_tähed(oletamisega):\n",
    "    rx = re.compile(r'(\\D)\\1{2,}')\n",
    "    rxx = rx.findall(oletamisega.text)\n",
    "    return len(rxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "detailed-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tundmatude sõnade osakaalu leidmine\n",
    "def luhemate_tundmatute_osakaal(oletamiseta):\n",
    "    analuusita = 0\n",
    "    koik = 0\n",
    "\n",
    "    vordlus = int(math.ceil(keskmised[\"keskmine_lemma_pikkus\"]*2))\n",
    "\n",
    "    for word in oletamiseta.words:\n",
    "        if word[\"analysis\"] == []:\n",
    "            if not all(char in string.punctuation for char in word[\"text\"]):\n",
    "                if len(word[\"text\"]) < vordlus:\n",
    "                    analuusita += 1\n",
    "                    \n",
    "    return analuusita / len(oletamiseta.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "loved-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esimese, teise ja kolmanda isiku osakaalu leidmine verbidest\n",
    "def verbide_isikute_osakaalud(oletamisega):\n",
    "    # Tunnuste lõpud, EstNLTK dokumentatsioonist\n",
    "    # Ei kordu omavahel\n",
    "    esi_tunnused = ['sime', 'me', 'nuksime', 'nuksin', 'gem', 'ksin', 'n', 'sin', 'ksime']\n",
    "    teine_tunnused = ['te', 'o', 'nuksite', 'd', 'site', 'ge', 'ksite']\n",
    "    kolmas_tunnused = ['s', 'gu', 'vad', 'b']\n",
    "    \n",
    "    # Loeb kokku isikute kaupa ja kõik isikud kokku\n",
    "    arv_koik = 0\n",
    "    arv_esimene = 0\n",
    "    arv_teine = 0\n",
    "    arv_kolmas = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis) == 1:\n",
    "            analysis = analysis[0]\n",
    "            # Kui tegu on verbiga\n",
    "            if analysis['partofspeech'] == \"V\":\n",
    "                #Jätab meelde sõnalõpu\n",
    "                form = analysis['form']\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                if form in esi_tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_esimene += 1\n",
    "                    continue\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                elif form in teine_tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_teine += 1\n",
    "                    continue\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                elif form in kolmas_tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_kolmas += 1\n",
    "                    continue\n",
    "    # Tagastab kõik kolm osaarvu\n",
    "    return arv_esimene/arv_koik, arv_teine/arv_koik, arv_kolmas/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "medieval-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esimese, teise ja kolmanda isiku osakaalu leidmine asesõnadest\n",
    "def aesõnade_isikute_osakaalud(oletamisega):\n",
    "    # Loeb kokku isikute kaupa ja kõik isikud kokku\n",
    "    arv_koik = 0\n",
    "    arv_esimene = 0\n",
    "    arv_teine = 0\n",
    "    arv_kolmas = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis) == 1:\n",
    "            analysis = analysis[0]\n",
    "            # Kui tegu on asesõnaga\n",
    "            if analysis['partofspeech'] == \"P\":\n",
    "                #Jätab meelde asesõna\n",
    "                lemma = analysis['lemma']\n",
    "                #Vaatab asesõna algvormi ja suurendab vastavat skoori\n",
    "                if lemma == 'mina':\n",
    "                    arv_koik += 1\n",
    "                    arv_esimene += 1\n",
    "                    continue\n",
    "                #Vaatab asesõna algvormi ja suurendab vastavat skoori\n",
    "                #Teietamine automaatselt sama, mis sinatamine (sina mitmuse analüüs)\n",
    "                elif lemma == 'sina':\n",
    "                    arv_koik += 1\n",
    "                    arv_teine += 1\n",
    "                    continue\n",
    "                #Vaatab asesõna algvormi ja suurendab vastavat skoori\n",
    "                elif lemma == 'tema':\n",
    "                    arv_koik += 1\n",
    "                    arv_kolmas += 1\n",
    "                    continue\n",
    "    # Tagastab kõik kolm osaarvu\n",
    "    return arv_esimene/arv_koik, arv_teine/arv_koik, arv_kolmas/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "departmental-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbisikuliste verbide osakaalu leidmine tekstist\n",
    "def passiivi_osakaal(oletamisega):\n",
    "    # Tunnuste lõpud, EstNLTK dokumentatsioonist\n",
    "    tunnused = ['takse', 'ti', 'tav', 'tuks', 'tagu', 'tama', 'tud', 'tuvat', 'tavat', 'taks', 'ta']\n",
    "    \n",
    "    # Loeb kokku isikute kaupa ja kõik isikud kokku\n",
    "    arv_koik = 0\n",
    "    arv_passiiv = 0\n",
    "    \n",
    "    # Vaatab iga sõna analüüsi\n",
    "    for analysis in oletamisega.analysis:\n",
    "        # Kui pole mitmese analüüsiga\n",
    "        if len(analysis) == 1:\n",
    "            analysis = analysis[0]\n",
    "            # Kui tegu on verbiga\n",
    "            if analysis['partofspeech'] == \"V\":\n",
    "                #Jätab meelde sõnalõpu\n",
    "                form = analysis['form']\n",
    "                # Vaatab, kas tunnus on loendis, ja suurendab vastavalt skoori\n",
    "                if form in tunnused:\n",
    "                    arv_koik += 1\n",
    "                    arv_passiiv += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    arv_koik += 1\n",
    "        # Kui on mitmese analüüsiga\n",
    "        else:\n",
    "            leidub_passiivne = False\n",
    "            # Vaatab kõiki analüüse\n",
    "            # Kui vähemalt üks on passiivi analüüsiga\n",
    "            # Märgib kogu leiduva vormi passiivseks\n",
    "            for analuus in analysis:\n",
    "                if analuus['partofspeech'] == \"V\":\n",
    "                    # Vaatab, kas tunnus on loendis, ja märgib, et järelikult on passiiviga\n",
    "                    if analuus['form'] in tunnused:\n",
    "                        leidub_passiivne = True\n",
    "                        break\n",
    "            \n",
    "            if leidub_passiivne:\n",
    "                arv_koik += 1\n",
    "                arv_passiiv += 1\n",
    "            else:\n",
    "                arv_koik += 1\n",
    "        \n",
    "    # Tagastab osaarvu\n",
    "    return arv_passiiv/arv_koik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bizarre-paintball",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-022ecdd08649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Arvutab faili kohta info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mfaili_info_salvestamine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-113-7fb510fb5cc6>\u001b[0m in \u001b[0;36mfaili_info_salvestamine\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mta_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moletamiseta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mmeta_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Karl Gustav Gailit\\anaconda3\\envs\\baka\\lib\\codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Algse kausta nimi, võtab sealt algsed failinimed, ei loe neid faile sisse\n",
    "source = \"etnc19_web_2019_100000/\"\n",
    "\n",
    "os.makedirs(os.path.dirname(\"etnc19_web_2019_andmed/\"), exist_ok=True)\n",
    "\n",
    "with open(\"keskmised.json\", \"r\", encoding = \"UTF-8\") as fr:\n",
    "    keskmised = json.load(fr)\n",
    "    \n",
    "# Avab järjest kõik failid algkaustas\n",
    "for file in [f for f in os.listdir(source)]:\n",
    "    # Arvutab faili kohta info\n",
    "    faili_info_salvestamine(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-think",
   "metadata": {},
   "source": [
    "Katsetamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fallen-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etnc19_web_2019_morf_oletamiseta\\www.etwinning.net_4188741_morf_oletamiseta.json\", \"r\", encoding = \"utf-8\") as fr:\n",
    "    oletamiseta = Text(json.load(fr))\n",
    "with open(\"etnc19_web_2019_morf_oletamisega\\www.1helin.wordpress.com_4952900_morf_oletamisega.json\", \"r\", encoding = \"utf-8\") as fr:\n",
    "    oletamisega = Text(json.load(fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "resident-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passiivi_osakaal(oletamisega)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
